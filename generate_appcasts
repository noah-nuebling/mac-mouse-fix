#!/usr/bin/python3

# Imports

import sys
import os
import shutil
# import requests # Only ships with python2 on mac it seems. Edit: So what? We could just install it right?
import urllib.request
import urllib.parse

from pathlib import Path

import json

import textwrap
from pprint import pprint

import subprocess

import re

import anthropic

import argparse


# TODO: [Mar 2025]
#   - [ ] Integrate this with our scripts repo
#       - [ ] Use it to validate the locales
#           - We can enforce that this repo should be in a folder like mac-mouse-fix-update-feed. The mac-mouse-fix repo, on the master branch, should be a in a sibling folder – Then we can read the locales from the xcode project.
#       - [ ] Replace subprocess and os.system calls with our 'safe' (non-shell) custom implementation. (Now that we're passing LLM output, shell=True isn't safe anymore I think.)
#   - [ ] For each locale, create folder of localized 'releases' md docs which mirror the GitHub releases page (including asset-download-links)
#   - [ ] Rename from generate_appcasts to something that reflects that it also creates 'release' documents now.
#   - Anthropic API: 
#       - Look into Batch Processing:   https://docs.anthropic.com/en/docs/build-with-claude/batch-processing
#       - Look into Prompt Caching:     https://docs.anthropic.com/en/docs/build-with-claude/prompt-caching
#       - Optimize Prompt / do 'prompt engineerig' (?)
#       - Optimize Model choice (?)
#       - Optimize Cost (?)
#           - I'll only run this once in a while, so it probably doesn't matter.
#       - See if there are other API params to optimize (?)
#       - Optimize latency (?)
#           - Not that important but current latency of like 30 s per request is annoying to work with. [Mar 2025]

"""
Protocol:  
  - [Mar 2025] 
        I machine translated 3.0.3 update notes using the following parameters:
            model:          claude-3-5-sonnet-20241022
            temperature:    0
            system: 
                You are an accurate, elegant translator. Requests that you handle follow the pattern:
                `language_code: <some ISO language code>\\nenglish_text: <some english text>`
                You will reply with the translation of the english text into the language specified by the language code. You do not reply with any other information. Only the translation.
                Context: The text you translate is written by the developer of an indie app. The text is intended to be read by users of said indie app. To be appropriate for this context, the text should not be overly formal. For example, when translating to German, use informal 'du' instead of formal 'Sie'.
            input: 
                f"language_code: {lcode}\nenglish_text: {release_notes_cleaned}"
                On {lcode}:
                    - I fed it 29 language_code's, extracted from the 'knownRegions' in the MMF Xcode project. (from the feature-strings-catalog branch)
                On {release_notes_cleaned}:
                    - Release notes were downloaded straight from the GitHub releases API, I then also stripped out HTML comments since those don't need to be translated.

        I then asked Claude 3.7 (with extended thinking) to thoroughly review the translations.
            - It said they were of excellent quality.
            - It noted that Korean, Japanese, and French use polite forms, which German uses informal 'du'. 
                - I asked it whether that makes sense and it explained that this culturally appropriate and matches trends seen in tech documentation and communication by tech companies.

        I also personally reviewed the German versions:
            - The translations sound very good and natural. Some stuff sounds weird, but I think that's mostly cause my original English texts aren't super well written. (I felt it was very apologetic and verbose in some places. I just felt like who caressss when reading it. But that's not the LLM-translator's fault.)

        -> It seems like this setup produces very good translations.
            (We haven't iterated on the prompt or other parameters, but I think we don't have to since this is good enough.)

        Caveats: 
            - When we use very specific terms mirroring UI elements in the app, that is unlikely to get accurately translated.
            - Solution ideas:
                1. Manual glossary: 
                    Have human translators of the main app create a glossary somehow
                2. Disclaimer: 
                    Mark the update notes as 'machine translated' and 'possibly containing some inaccuracies'
                    -> I think people generally appreciate knowing whether the content they look at is AI generated.
                3. Flood LLM context: 
                    Feed all the (human generated) translations from the app and the website into the LLM's context window
                    - Problems: 
                        - Bigger load on the API (Should probably use 'prompt caching'.)
                        - Might degrade the quality if we clutter up the context window
                        - Not sure how handle older UI elements get removed? Then we can't easily update older notes anymore I think. I guess we could feed it different versions of the human generated translations but then we won't be able to employ prompt caching I think and it would complicated everything.
                        - For a lot of the strings in the main MMF app, the primary context for the translators stems from the autogenerated screenshots with markers for where the specific string appears in the screenshot - Might not be feasible to feed this context to the LLM.
                        -> Even with these problems, feeding the human translations as context might still bring worth-it quality improvements.
                4. 'Dynamic glossary':
                    - In this script we'd maintain a 'glossary_keys' list and then we'd extract the English original + translations for those keys from the .xcstrings files 
                      in the 'mac-mouse-fix' repo and paste them into the LLM's context. 
                    -> This should be easy to maintain and make translations quality really good.
                    - Problems:
                        - When older strings referenced by the glossary_keys get removed, we might need special handling -> Could probably just hardcode the latest commit where a specific string is available.

                -> Conclusion: Start with 2. (Disclaimer) and perhaps add 4. (Dynamic glossary) later to improve quality.
"""

# Parse args
argparser = argparse.ArgumentParser("")
argparser.add_argument('--test-mode', action=argparse._StoreTrueAction)
argparser.add_argument('--anthropic-api-key', default=os.environ.get("ANTHROPIC_API_KEY"))
args = argparser.parse_args()

# Test mode
TEST_MODE = False
if len(sys.argv) >= 2 and sys.argv[1] == '--test-mode':
    print('Running in --test-mode')
    TEST_MODE = True

# Constants
#   Paths are relative to project root or to each other.

# URLs
releases_api_url        = "https://api.github.com/repos/noah-nuebling/mac-mouse-fix/releases"

if TEST_MODE:
    base_url            = "http://127.0.0.1:8000"       # For testing. Run `python3 -m http.server 8000` to serve this repo at that url. Background: `file://` and `localhost:` URLs are forbidden by Sparkle, this is a workaround. Read more in README.md. Stand [Feb 2025]
else:
    base_url            = "https://raw.githubusercontent.com/noah-nuebling/mac-mouse-fix/update-feed"

if False:
    proxy_url               = "https://noah-nuebling.github.io/mmf-update-notes-proxy/?url="
    raw_github_url      = "https://raw.githubusercontent.com/noah-nuebling/mac-mouse-fix/master"

# Output paths/folders
appcast_file_name               = "appcast.xml"                             # Path to the appcast for stable releases
appcast_pre_file_name           = "appcast-pre.xml"                         # Path to the appcast for prereleases

appcast_url                     = f"{base_url}/{appcast_file_name}"         # This gets included as a link in appcast.xml. Not sure what it does.
appcast_pre_url                 = f"{base_url}/{appcast_pre_file_name}"

update_notes_folder_markdown    = "update-notes/md"                          # This is where the md update notes go. The English versions are extracted from GitHub releases, and the translations are automatically generated by this script.
update_notes_folder_html        = "update-notes/html"                        # This is where the html update notes go. They are generated from the .md update notes downloaded off GitHub. appcast.xml will reference these html update notes via <sparkle:releaseNotesLink>
css_file_path                   = "update-notes/style.css"                   # The css file referenced by the html update notes.
js_file_path                    = "update-notes/script.js"

# Implementation detail paths/folders

sparkle_project_path            = "Frameworks/Sparkle-1.27.3"                       # Need this to use Sparkles code-signing tool # This is dangerously hardcoded # Might be smart to keep this in sync with the Sparkle version in the app.
download_folder                 = "generate_appcasts_downloads"                     # This is were we download old app versions to, and then unzip them. We want to delete this on exit.
app_bundle_name                 = "Mac Mouse Fix.app"                               # This is the name of the app bundle after unzipping it
html_header_includes_tmp_file   = f"{download_folder}/html_header_includes.html"    # Temp file for storing html headers for update notes. I guess we're using downloads_folder as a general 'tmp' folder here.

info_plist_app_subpath          = "Contents/Info.plist"         # Where to look fo the Info.plist file within the unzipped app bundle

prefpane_bundle_name            = "Mouse Fix.prefpane"                     # App has been renamed, this is the old name

# Dynamic paths/folders
current_directory = os.getcwd()
download_folder_absolute = os.path.join(current_directory, download_folder)

# Language codes
#   ISO codes for the languages to translate the update notes into. 
#   Keep in-sync with 'knownRegions' in project.pbxproject of mac-mouse-fix and mac-mouse-fix-website repos:
#       https://github.com/noah-nuebling/mac-mouse-fix/blob/b3c2cb85f81e8637d51b533a43bbc99084e85e89/Mouse%20Fix.xcodeproj/project.pbxproj#L7954
#   (TODO: Perhaps automatically sync the languages with the mac-mouse-fix-website repo – we can expect to find that as a sibling folder to the one where this script runs.)

source_language_code = 'en'

language_codes = [
    'en',
    'de',
    "zh-Hant",
    "zh-HK",
    "zh-Hans",
    'ko',
    'vi',
    'ar',
    'ca',
    'cs',
    'nl',
    'fr',
    'el',
    'he',
    'hu',
    'it',
    'ja',
    'pl',
    "pt-BR",
    "pt-PT",
    'ro',
    'ru',
    'es',
    'sv',
    'tr',
    'uk',
    'th',
    'id',
    'hi',
]

# Stuff for reading directly from the project source files. 
#   We went over to downloading and unzipping all old bundles instead.
#   Note: 
#       Accessing Xcode environment variables is night impossible it seems
#       The only way to do it I found is described here:
#         https://stackoverflow.com/questions/6523655/how-do-you-access-xcode-environment-and-build-variables-from-an-external-script
#         And that's not feasible to do for old versions.

if False:
    info_plist_path = "App/SupportFiles/Info.plist"
    base_xcconfig_path = "xcconfig/Base.xcconfig"
    files_to_checkout = [info_plist_path, base_xcconfig_path]

def generate():
    try:

        # Check if there are uncommited changes
        #   Note: This script uses git stash several times, so they'd be lost Update: [Feb 2025] We don't seem to be using git stash anymore. We can probably turn this off. (./update still checks for uncommited changes, so that should be safe.)
        if TEST_MODE or True:
            pass
        else: 
            uncommitted_changes = subprocess.check_output('git diff-index HEAD --', shell=True).decode('utf-8')
            if (len(uncommitted_changes) != 0):
                raise Exception('There are uncommited changes. Please commit or stash them before running this script.')

        # Main logic
        
        # Call GH API
        with urllib.request.urlopen(releases_api_url) as request:
            releases = json.load(request)

        # Make downloads folder
        os.makedirs(download_folder_absolute, exist_ok=True)

        # Prepare text to include in the html header of all release notes.
        #   (We have to write this to a file because I don't know how else to pass this to pandoc.)
        
        if True: 
            # Approach 1: Reference the css/js files
            #   This only works through githack, because raw.githubusercontent serves the css and js file with text/plain mime type.
            #   
            #   Meta: Is this better than embedding the css/js files directly? 
            #       Contra: The client will have to download the css/js either way to correctly display the update notes. So that's not better.
            #       Pro: The html files inside update-notes/html will be smaller, since they don't all contain a copy of our css/js.
            #       Pro: The *content* in the html files can be updated and diff'd independently of the js/css. This might make it easier to programmatically check for content changes, which might be useful once we translate the update-notes with the help of an LLM but don't wanna regenerate translations if the content didn't change.
            #       Contra: This might **slow down** loading of update notes because we need to download 3 different files through githack. 
            #           But based on [Feb 2025] testing, the slow down is not noticable. Specifically, I saw that: 1. BetterDisplay, another Sparkle app also take a bit to load the notes 2. When you load a note in the browser, it's instant, despite css and js being served through githack. -> So I don't feel like githack makes a difference.
            
            html_header_includes = textwrap.dedent("""\
            <link rel="stylesheet" href="{css_slot}"/>
            <script src="{js_slot}"></script>\
            """).format(
                css_slot = apply_githack(f'{base_url}/{css_file_path}'),
                js_slot = apply_githack(f'{base_url}/{js_file_path}')
            )
        else: 
            # Approach 2: include the css/js files directly
            html_header_includes = textwrap.dedent("""\
            <style> 
            {css_slot} 
            </style>
            <script> 
            {js_slot} 
            </script>\
            """).format(css_slot = textwrap.indent(Path(css_file_path).read_text(), 4 * ' '), 
                        js_slot = textwrap.indent(Path(js_file_path).read_text(), 4 * ' '))
        
        with open(html_header_includes_tmp_file, 'w') as f:
            f.write(html_header_includes)

        # We'll be iterating over all releases and collecting data to put into the appcast
        appcast_items = []
        appcast_pre_items = [] # Items for the pre-release channel

        for r in releases:

            # Get short version
            short_version = r['name']
        
            # Log
            print(f'Processing release {short_version}...')

            # Get tag name
            tag_name = r['tag_name']

            # Get release notes
            release_notes = r['body'] # This is markdown
            
            # Get path to cached English release notes
            md_path_src = os.path.join(update_notes_folder_markdown, source_language_code, tag_name + ".md")

            # Compare to cached release notes
            cached_release_notes_differ = True
            try:
                old_release_notes = Path(md_path_src).read_text()
                cached_release_notes_differ = old_release_notes == release_notes
            except Exception as e:
                print(f"Comparing to cached release notes failed with error: {e}")
            
            # Write md release notes to cache
            #   Note: As a plain string I had trouble passing it to pandoc, because I couldn't escape it properly
            os.makedirs(os.path.dirname(md_path_src), exist_ok=True)
            with open(md_path_src, "w") as f:
                f.write(release_notes)
            
            # Translate release notes
            def do_translation():               # Wrapping this in a function because python doesn't have goto
                user_allowed_all = False
                for lcode in language_codes:
                    
                    # Skip English
                    if lcode == source_language_code: continue

                    # Get path for translated md file
                    translation_path = os.path.join(update_notes_folder_markdown, lcode, tag_name + ".md")

                    # Skip translation if it's still up-to-date
                    if not cached_release_notes_differ and os.path.exists(translation_path):
                        print(f"Skipping translation to {lcode} since cache at '{md_path_src}' is still up-to-date, and a translation already exists at '{translation_path}'.")
                        continue

                    # Confirm translation with user
                    do_translate = None
                    if user_allowed_all:
                        do_translate = True
                    else:
                        while True:
                            user_input = input(f"Translate release notes for version {tag_name} to language {lcode}? (Might incur API costs) [y/n/a - a to translate to all remaining languages without asking again.]")
                            if   user_input == 'y': do_translate = True
                            elif user_input == 'n': do_translate = False
                            elif user_input == 'a': do_translate = True; user_allowed_all = True
                            else:                   print(f'Error: Input {user_input} unrecognised.'); continue
                            break
                    assert do_translate is not None, "Code is buggy"

                    if do_translate:
                        
                        # Log
                        print(f"Translating to {lcode}")

                        # Lazily create anthropic client (Store it on the function object)
                        if not hasattr(do_translation, "anthropic_client"):
                            api_key = args.anthropic_api_key
                            assert api_key is not None, "Error: No anthropic API key found (Provide it via arg or environment var)."
                            do_translation.anthropic_client = anthropic.Anthropic(api_key=api_key)
                            assert do_translation.anthropic_client is not None, f"Error: No anthropic API client couldn't be created. api_key: {api_key}"
                        anthropic_client = do_translation.anthropic_client

                        # Remove HTML comments, since those don't have to be translated
                        release_notes_cleaned =  re.sub(r"<!--.*?-->", "", release_notes, count=0, flags=re.DOTALL)

                        # Constant: Max output tokens
                        #   Discussion: [Mar 2025]
                        #   - The `3.0.1 Beta 1` notes have a bit over 1000 tokens.
                        #   - 8192 is currently the max. That seems sorta low? But should be enough for our usecase. 
                        #   - If we reach the limit, the stop_reason is set to 'max_tokens'
                        max_output_tokens = 8192
                        
                        # Create request for anthropic API
                        anthropic_args = {
                            'model':        "claude-3-5-sonnet-20241022",
                            'system':       textwrap.dedent(
                                """\
                                You are an accurate, elegant translator. Requests that you handle follow the pattern: \
                                `language_code: <some ISO language code>\\nenglish_text: <some english text>`
                                You will reply with the translation of the english text into the language specified by the language code. You do not reply with any other information. Only the translation.
                                Context: The text you translate is written by the developer of an indie app. The text is intended to be read by users of said indie app. To be appropriate for this context, the text should not be overly formal. For example, when translating to German, use informal 'du' instead of formal 'Sie'.\
                                """
                            ),
                            'messages': [{
                                "role": "user",
                                "content": [
                                    {
                                        "type": "text",
                                        "text": f"language_code: {lcode}\nenglish_text: {release_notes_cleaned}"
                                    }
                                ]
                            }]
                        }

                        # Get input token count
                        input_token_count_response = anthropic_client.messages.count_tokens(**anthropic_args)
                        input_token_count = input_token_count_response.input_tokens
                        
                        # Log
                        print(f"Sending request to anthropic with {input_token_count} input tokens...")

                        # Ping Anthropic
                        anthropic_args = { 
                            **anthropic_args, 
                            'max_tokens':   max_output_tokens,
                            'temperature':  0,
                        }
                        response = anthropic_client.messages.create(**anthropic_args)
                        
                        # Validate response
                        assert response.stop_reason == 'end_turn', f"Anthropic model stopped with unexpected reason '{response.stop_reason}'"
                        
                        # Extract translation text
                        translation = response.content[0].text
                        
                        # Log
                        print(f"Writing translation to {translation_path}...")

                        # Write translation to file
                        p = Path(translation_path)
                        p.parent.mkdir(parents=True, exist_ok=True)
                        p.write_text(translation)

            do_translation()

            # Iterate through all translated md files
            for lcode in language_codes:
                
                # Log
                print()

                # Convert release notes to HTML 
                md_path: Path = Path() / update_notes_folder_markdown / lcode / (tag_name + '.md')
                release_notes_html = subprocess.check_output(
                    f"cat {str(md_path)} | "
                    "pandoc "
                    "--from markdown --to html "
                    "--standalone "                 # Not sure what this does / if it's necessary
                    f"--include-in-header ./{html_header_includes_tmp_file} "
                    "--metadata title='' "
                    "--metadata document-css=false" # Stops pandoc from adding some of its default inline css, but can't manage to turn that off entirely.
                    ,
                    shell=True).decode('utf-8')

                # Get path
                html_path: Path = Path() / update_notes_folder_html / lcode / (tag_name + '.html')
                
                # Compare
                if html_path.read_text() == release_notes_html:
                    print(f"HTML release notes at '{html_path}' were already up-to-date")
                else:
                    print(f"Updating HTML release notes at '{html_path}'")
                    html_path.parent.mkdir(parents=True, exist_ok=True)
                    html_path.write_text(release_notes_html)


            # Get title
            title = f"{short_version} available!"

            # Get publishing date
            publishing_date = r['published_at'];

            # Get isPrerelease
            is_prerelease = r['prerelease']

            # Get type
            type = "application/octet-stream" # Not sure what this is or if this is right

            # Get localized release notes ?
            #   ...

            if False:

                # Tried to checkout each commit and then read bundle version and minimum compatible macOS version from the local Xcode source files. 
                # I had trouble making this approach work, though, so we went over to just unzipping each update and reading that data directly from the bundle

                # Get commit number
                # commit = os_system_exc(f"git rev-list -n 1 {tag_name}") # Can't capture the output of this for some reason
                commit_number = subprocess.check_output(f"git rev-list -n 1 {tag_name}", shell=True).decode('utf-8')
                commit_number = commit_number[0:-1] # There's a linebreak at the end

                # Check out commit
                # This would probably be a lot faster if we only checked out the files we need
                os_system_exc("git stash")
                files_string = ' '.join(files_to_checkout)
                bash_string = f"git checkout {commit_number} {files_string}"
                try:
                    subprocess.check_output(bash_string)
                except Exception as e:
                    print(f"Exception while checking out commit {commit_number} ({short_version}): {e}. Skipping this release.")
                    continue

                # Get version
                #   Get from Info.plist file
                bundle_version = subprocess.check_output(f"/usr/libexec/PlistBuddy {info_plist_path} -c 'Print CFBundleVersion'", shell=True).decode('utf-8')

                # Get minimum macOS version
                #   The environment variable buried deep within project.pbxproj. No practical way to get at this
                #   Instead, we're going to hardcode this for old versions and define a new env variable via xcconfig we can reference here for newer verisons
                #   See how alt-tab-macos did it here: https://github.com/lwouis/alt-tab-macos/blob/master/config/base.xcconfig
                minimum_macos_version = ""
                try:
                    minimum_macos_version = subprocess.check_output(f"awk -F ' = ' '/MACOSX_DEPLOYMENT_TARGET/ {{ print $2; }}' < {base_xcconfig_path}", shell=True).decode('utf-8')
                    minimum_macos_version = minimum_macos_version[0:-1] # Remove trailing \n character
                except:
                    minimum_macos_version = 10.11

            # Get app asset
            # NOTE: This has a copy in stats_internal.py. Keep them in sync.
            app_assets = [asset for asset in r['assets'] if asset['name'] == 'MacMouseFixApp.zip' or asset['name'] == 'MacMouseFix.zip'] # I don't think we need `MacMouseFix.zip` here (That's the old prefpane name.)
            assert len(app_assets) <= 1, f"Found {len(app_assets)} app assets. Here are the asset names: { list(map(lambda a: a['name'], r['assets'])) }"
            if len(app_assets) == 0:
                print(f"Couldn't find asset with standard name. Falling back to first asset, named {r['assets'][0]['name']}")
                app_assets = [r['assets'][0]]
            
            # Get download link
            download_link = app_assets[0]['browser_download_url']

            # Download update
            download_name = download_link.rsplit('/', 1)[-1]
            download_zip_path = f'{download_folder}/{download_name}'
            urllib.request.urlretrieve(download_link, download_zip_path)

            # Get edSignature
            signature_and_length = subprocess.check_output(f"./{sparkle_project_path}/bin/sign_update {download_zip_path}", shell=True).decode('utf-8')
            signature_and_length = signature_and_length[0:-1]

            # Unzip update
            os_system_exc(f'ditto -x -k --sequesterRsrc --rsrc "{download_zip_path}" "{download_folder}"') # This works, while subprocess.check_output() doesn't for some reason

            # Find app bundle
            #   Maybe we could just name the unzipped folder instead of guessing here
            #   Well we also use this to determine if the download is a prefpane or an app. There might be better ways to infer this but this should work
            is_prefpane = False
            app_path = f'{download_folder}/{app_bundle_name}'
            if not os.path.exists(app_path):
                app_path = f'{download_folder}/{prefpane_bundle_name}'
                if not os.path.exists(app_path):
                    raise Exception('Unknown bundle name after unzipping')
                else:
                    is_prefpane = True

            if is_prefpane:
                continue

            # Find Info.plist in app bundle
            info_plist_path = f'{app_path}/{info_plist_app_subpath}'

            # Read stuff from Info.plist
            bundle_version = subprocess.check_output(f"/usr/libexec/PlistBuddy '{info_plist_path}' -c 'Print CFBundleVersion'", shell=True).decode('utf-8')
            minimum_macos_version = subprocess.check_output(f"/usr/libexec/PlistBuddy '{info_plist_path}' -c 'Print LSMinimumSystemVersion'", shell=True).decode('utf-8')
            bundle_version = bundle_version[0:-1]
            minimum_macos_version = minimum_macos_version[0:-1]

            # Delete bundle we just processed so that we won't accidentally process it again next round (that happens if the next bundle has prefpane_bundle_name instead of app_bundle_name)
            shutil.rmtree(app_path)

            # Assemble collected data into appcast.xml-ready item-string
            #  
            #   About release notes & appcast.xml format:
            #       Release notes can be embedded directly in the appcast.xml using <description> or via a link using <sparkle:releaseNotesLink>
            #           Originally, we used <description> to keep things simple, but this caused the appcast.xml to contain countless copies of our custom css and js text.
            #           I couldn't figure out how to fix that without switching to <sparkle:releaseNotesLink>, so we did switch in [Feb 2025]
            #       
            #   <sparkle:releaseNotesLink> complications:
            #   - [Feb 2025] We're prepending base_url, because I don't think the <sparkle:releaseNotesLink> can be a relative URL. 
            #   - [Feb 2025] <sparkle:releaseNotesLink> requires githack since raw.githubusercontent serves the html file with text/plain mime type, which makes Sparkle update window in MMF display the html source code as plain text.
            #       - Before githack, we used a custom proxy to change mime-types, but it worked clientside and so required js which wasn't activated in the update window of older MMF versions.
            #       - See: https://github.com/noah-nuebling/mmf-update-notes-proxy

            #   References: 
            #       - [SUAppcastItem releaseNotesURL] docs (https://sparkle-project.org/documentation/api-reference/Classes/SUAppcastItem.html#/c:objc(cs)SUAppcastItem(py)releaseNotesURL)
            #           - Explains difference between <sparkle:releaseNotesLink> and <description>
            #       - SampleAppcast.xml 1 (https://github.com/sparkle-project/Sparkle/blob/2.x/Resources/SampleAppcast.xml)
            #           - Contained in main Sparkle repo, uses <sparkle:releaseNotesLink>
            #       - SampleAppcast.xml 2 (https://sparkle-project.org/files/sparkletestcast.xml)
            #           - Linked from Sparkle docs, uses <description>

            if True:
                # Approach 1: <sparkle:releaseNotesLink>
                #   (Requires githack to fix mime type)
                release_notes_str = "<sparkle:releaseNotesLink>{release_notes_link_slot}</sparkle:releaseNotesLink>".format(
                    release_notes_link_slot = apply_githack(f"{base_url}/{html_path}")
                )
            else:
                # Approach 2: <description>
                #   (This bloats the appcast file quite a lot)
                release_notes_str = textwrap.dedent("""\
                <description>
                {release_notes_slot}
                </description>\
                """).format(release_notes_slot = release_notes_html)

            item_string = textwrap.dedent("""\
            <item>
                <title>{title_slot}</title>
                <pubDate>{publishing_date_slot}</pubDate>
                <sparkle:minimumSystemVersion>{minimum_macos_version_slot}</sparkle:minimumSystemVersion>
                {release_notes_str_slot}
                <enclosure
                    url=\"{download_link_slot}\"
                    sparkle:version=\"{bundle_version_slot}\"
                    sparkle:shortVersionString=\"{short_version_slot}\"
                    {signature_and_length_slot}
                    type=\"{type_slot}\"
                />
            </item>\
            """).format(
                title_slot                  = title,
                publishing_date_slot        = publishing_date,
                minimum_macos_version_slot  = minimum_macos_version,
                release_notes_str_slot      = release_notes_str,
                download_link_slot          = download_link,
                bundle_version_slot         = bundle_version,
                short_version_slot          = short_version,
                signature_and_length_slot   = signature_and_length,
                type_slot                   = type
            )

            # Append item_string to arrays
            if not is_prerelease:
                appcast_items.append(item_string)

            appcast_pre_items.append(item_string)

        # Assemble item strings into final appcast strings
        appcast_content_string = textwrap.dedent('''\
        <?xml version="1.0" encoding="utf-8"?>
        <rss version="2.0" xmlns:sparkle="http://www.andymatuschak.org/xml-namespaces/sparkle"  xmlns:dc="http://purl.org/dc/elements/1.1/">
        <channel>
            <title>Mac Mouse Fix Update Feed</title>
            <link>{}</link>
            <description>Stable releases of Mac Mouse Fix</description>
            <language>en</language>
            {}
        </channel>
        </rss>\
        ''').format(appcast_url, '\n'.join(appcast_items))

        appcast_pre_content_string = textwrap.dedent('''\
        <?xml version="1.0" encoding="utf-8"?>
        <rss version="2.0" xmlns:sparkle="http://www.andymatuschak.org/xml-namespaces/sparkle"  xmlns:dc="http://purl.org/dc/elements/1.1/">
          <channel>
            <title>Mac Mouse Fix Update Feed for Prereleases</title>
            <link>{}</link>
            <description>Prereleases of Mac Mouse Fix</description>
            <language>en</language>
            {}
          </channel>
        </rss>\
        ''').format(appcast_pre_url, '\n'.join(appcast_pre_items))

        # Write to file
        with open(appcast_file_name, "w") as f:
            f.write(appcast_content_string)
        with open(appcast_pre_file_name, "w") as f:
            f.write(appcast_pre_content_string)

        # Cleanup & exit
        clean_up(download_folder)
        exit(0)

    except Exception as e: # Exit immediately if anything goes wrong
        print(e)
        clean_up(download_folder)
        exit(1)

def clean_up(download_folder):
    ret = os.system(f'rm -R {download_folder}')
    if ret != 0:
        print(f'Clean up failed with error code: {ret}')

def apply_githack(url: str):
    # Notes: 
    #   - Based on raw.githack.com, they have very good uptime and have been running for over 10 years (copyright is from 2013) – So I think it's ok to rely on that service.
    #   - raw.githack.com/faq strongly recommends using rawcdn.githack.com in production (instead of raw.githack.com), but that requires us to know the git commit and manually update URLs when content changes (if I understood correctly) – which would complicate the logic here.
    #     Discussion:
    #       Specifically raw.githack.com says: "Please use CDN URLs for anything that might result in heavy traffic. [...] If you don't and the service gets a lots of requests from the same domain, all further requests will be temporary redirected to corresponding CDN URLs"
    #       I assume this is to prevent costs on their side.
    #       I assume traffic from the Sparkle update window in MMF wouldn't trigger the CDN fallback, since the traffic wouldn't come from 'the same domain'. But I'm not sure. If the fallback does trigger, it could delay the rollout of changes we make to update notes. It could also perhaps cause other problems I can't think of right now.
    #       However, I still think it's ok to not use the CDN URL here, since the traffic generated by MMF should be quite low.
    #       I tested with Little Snitch in [Feb 2024] using a newer MMF build (I believe it used Sparkle 1.27): And it seems that githack is only pinged when the update notes are actually showed to the user – When no update is found, then githack is not pinged.
    #       When githack is pinged, it will serve the html, css, and js for the update notes for exactly one update. Looking at the size of those files, this should only be a few KB of traffic.
    #           -> Based on this, I believe the traffic to githack should be pretty miniscule, and therefore I assume it's ok to *not* use the CDN URL.
    #           -> I also set up a 10$-per-month patreon donation for the githack maintainer in [Feb 2025]. I assume that will (more than) offset any costs caused by this.

    if TEST_MODE:
        return url  # In TEST_MODE we host the files locally and they'll be served with the right mime type
    else:
        return url.replace('raw.githubusercontent.com', 'raw.githack.com')

def os_system_exc(s): 
    ret = os.system(s)
    if ret != 0:
        raise Exception(f"os.system failed with error code {ret}")

generate()